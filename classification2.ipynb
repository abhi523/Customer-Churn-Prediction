{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification on the dataset where null values are filled with mean and mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/abhi/spark-2.2.1-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('classifier').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe = spark.read.csv('/home/abhi/project/cleaned_data_d3/d3.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schema of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Var6: integer (nullable = true)\n",
      " |-- Var7: integer (nullable = true)\n",
      " |-- Var13: integer (nullable = true)\n",
      " |-- Var21: integer (nullable = true)\n",
      " |-- Var22: integer (nullable = true)\n",
      " |-- Var24: integer (nullable = true)\n",
      " |-- Var25: integer (nullable = true)\n",
      " |-- Var28: double (nullable = true)\n",
      " |-- Var35: integer (nullable = true)\n",
      " |-- Var38: integer (nullable = true)\n",
      " |-- Var44: integer (nullable = true)\n",
      " |-- Var57: double (nullable = true)\n",
      " |-- Var65: integer (nullable = true)\n",
      " |-- Var72: integer (nullable = true)\n",
      " |-- Var73: integer (nullable = true)\n",
      " |-- Var74: integer (nullable = true)\n",
      " |-- Var76: integer (nullable = true)\n",
      " |-- Var78: integer (nullable = true)\n",
      " |-- Var81: double (nullable = true)\n",
      " |-- Var83: integer (nullable = true)\n",
      " |-- Var85: integer (nullable = true)\n",
      " |-- Var94: integer (nullable = true)\n",
      " |-- Var109: integer (nullable = true)\n",
      " |-- Var112: integer (nullable = true)\n",
      " |-- Var113: double (nullable = true)\n",
      " |-- Var119: integer (nullable = true)\n",
      " |-- Var123: integer (nullable = true)\n",
      " |-- Var125: integer (nullable = true)\n",
      " |-- Var126: integer (nullable = true)\n",
      " |-- Var132: integer (nullable = true)\n",
      " |-- Var133: integer (nullable = true)\n",
      " |-- Var134: integer (nullable = true)\n",
      " |-- Var140: integer (nullable = true)\n",
      " |-- Var143: integer (nullable = true)\n",
      " |-- Var144: integer (nullable = true)\n",
      " |-- Var149: integer (nullable = true)\n",
      " |-- Var153: integer (nullable = true)\n",
      " |-- Var160: integer (nullable = true)\n",
      " |-- Var163: integer (nullable = true)\n",
      " |-- Var173: integer (nullable = true)\n",
      " |-- Var181: integer (nullable = true)\n",
      " |-- Var189: integer (nullable = true)\n",
      " |-- Var192: string (nullable = true)\n",
      " |-- Var193: string (nullable = true)\n",
      " |-- Var195: string (nullable = true)\n",
      " |-- Var196: string (nullable = true)\n",
      " |-- Var197: string (nullable = true)\n",
      " |-- Var198: string (nullable = true)\n",
      " |-- Var199: string (nullable = true)\n",
      " |-- Var200: string (nullable = true)\n",
      " |-- Var202: string (nullable = true)\n",
      " |-- Var203: string (nullable = true)\n",
      " |-- Var204: string (nullable = true)\n",
      " |-- Var205: string (nullable = true)\n",
      " |-- Var206: string (nullable = true)\n",
      " |-- Var207: string (nullable = true)\n",
      " |-- Var208: string (nullable = true)\n",
      " |-- Var210: string (nullable = true)\n",
      " |-- Var211: string (nullable = true)\n",
      " |-- Var212: string (nullable = true)\n",
      " |-- Var214: string (nullable = true)\n",
      " |-- Var216: string (nullable = true)\n",
      " |-- Var217: string (nullable = true)\n",
      " |-- Var218: string (nullable = true)\n",
      " |-- Var219: string (nullable = true)\n",
      " |-- Var220: string (nullable = true)\n",
      " |-- Var221: string (nullable = true)\n",
      " |-- Var222: string (nullable = true)\n",
      " |-- Var223: string (nullable = true)\n",
      " |-- Var225: string (nullable = true)\n",
      " |-- Var226: string (nullable = true)\n",
      " |-- Var227: string (nullable = true)\n",
      " |-- Var228: string (nullable = true)\n",
      " |-- Var229: string (nullable = true)\n",
      " |-- Label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of attributes in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of rows in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = dataframe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler,OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifying the columns based on the type of data present in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "string_list = []\n",
    "num_list = []\n",
    "for name,dtype in dataframe.dtypes:\n",
    "    if(dtype == 'string'):\n",
    "        string_list.append(name)\n",
    "    if(dtype != 'string'):\n",
    "        num_list.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## appending the column name label to string list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "string_list.append('Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list of the columns that contain categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var192',\n",
       " 'Var193',\n",
       " 'Var195',\n",
       " 'Var196',\n",
       " 'Var197',\n",
       " 'Var198',\n",
       " 'Var199',\n",
       " 'Var200',\n",
       " 'Var202',\n",
       " 'Var203',\n",
       " 'Var204',\n",
       " 'Var205',\n",
       " 'Var206',\n",
       " 'Var207',\n",
       " 'Var208',\n",
       " 'Var210',\n",
       " 'Var211',\n",
       " 'Var212',\n",
       " 'Var214',\n",
       " 'Var216',\n",
       " 'Var217',\n",
       " 'Var218',\n",
       " 'Var219',\n",
       " 'Var220',\n",
       " 'Var221',\n",
       " 'Var222',\n",
       " 'Var223',\n",
       " 'Var225',\n",
       " 'Var226',\n",
       " 'Var227',\n",
       " 'Var228',\n",
       " 'Var229',\n",
       " 'Label']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using string indexer to convert the categorical data into numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(dataframe) for column in string_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using pipeline to execute the operation in stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=indexers)\n",
    "df_r = pipeline.fit(dataframe).transform(dataframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the list of columns(categorical) that are converted into numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for name,dtype  in df_r.dtypes:\n",
    "    if(name.endswith('_index')):\n",
    "         index_list.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using onehotencoder to convert the categorical data into vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = [OneHotEncoder(inputCol=column, outputCol=column+\"vec\") for column in index_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=encoders)\n",
    "df_r = pipeline.fit(df_r).transform(df_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schema of the dataframe after applying onehotencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Var6: integer (nullable = true)\n",
      " |-- Var7: integer (nullable = true)\n",
      " |-- Var13: integer (nullable = true)\n",
      " |-- Var21: integer (nullable = true)\n",
      " |-- Var22: integer (nullable = true)\n",
      " |-- Var24: integer (nullable = true)\n",
      " |-- Var25: integer (nullable = true)\n",
      " |-- Var28: double (nullable = true)\n",
      " |-- Var35: integer (nullable = true)\n",
      " |-- Var38: integer (nullable = true)\n",
      " |-- Var44: integer (nullable = true)\n",
      " |-- Var57: double (nullable = true)\n",
      " |-- Var65: integer (nullable = true)\n",
      " |-- Var72: integer (nullable = true)\n",
      " |-- Var73: integer (nullable = true)\n",
      " |-- Var74: integer (nullable = true)\n",
      " |-- Var76: integer (nullable = true)\n",
      " |-- Var78: integer (nullable = true)\n",
      " |-- Var81: double (nullable = true)\n",
      " |-- Var83: integer (nullable = true)\n",
      " |-- Var85: integer (nullable = true)\n",
      " |-- Var94: integer (nullable = true)\n",
      " |-- Var109: integer (nullable = true)\n",
      " |-- Var112: integer (nullable = true)\n",
      " |-- Var113: double (nullable = true)\n",
      " |-- Var119: integer (nullable = true)\n",
      " |-- Var123: integer (nullable = true)\n",
      " |-- Var125: integer (nullable = true)\n",
      " |-- Var126: integer (nullable = true)\n",
      " |-- Var132: integer (nullable = true)\n",
      " |-- Var133: integer (nullable = true)\n",
      " |-- Var134: integer (nullable = true)\n",
      " |-- Var140: integer (nullable = true)\n",
      " |-- Var143: integer (nullable = true)\n",
      " |-- Var144: integer (nullable = true)\n",
      " |-- Var149: integer (nullable = true)\n",
      " |-- Var153: integer (nullable = true)\n",
      " |-- Var160: integer (nullable = true)\n",
      " |-- Var163: integer (nullable = true)\n",
      " |-- Var173: integer (nullable = true)\n",
      " |-- Var181: integer (nullable = true)\n",
      " |-- Var189: integer (nullable = true)\n",
      " |-- Var192: string (nullable = true)\n",
      " |-- Var193: string (nullable = true)\n",
      " |-- Var195: string (nullable = true)\n",
      " |-- Var196: string (nullable = true)\n",
      " |-- Var197: string (nullable = true)\n",
      " |-- Var198: string (nullable = true)\n",
      " |-- Var199: string (nullable = true)\n",
      " |-- Var200: string (nullable = true)\n",
      " |-- Var202: string (nullable = true)\n",
      " |-- Var203: string (nullable = true)\n",
      " |-- Var204: string (nullable = true)\n",
      " |-- Var205: string (nullable = true)\n",
      " |-- Var206: string (nullable = true)\n",
      " |-- Var207: string (nullable = true)\n",
      " |-- Var208: string (nullable = true)\n",
      " |-- Var210: string (nullable = true)\n",
      " |-- Var211: string (nullable = true)\n",
      " |-- Var212: string (nullable = true)\n",
      " |-- Var214: string (nullable = true)\n",
      " |-- Var216: string (nullable = true)\n",
      " |-- Var217: string (nullable = true)\n",
      " |-- Var218: string (nullable = true)\n",
      " |-- Var219: string (nullable = true)\n",
      " |-- Var220: string (nullable = true)\n",
      " |-- Var221: string (nullable = true)\n",
      " |-- Var222: string (nullable = true)\n",
      " |-- Var223: string (nullable = true)\n",
      " |-- Var225: string (nullable = true)\n",
      " |-- Var226: string (nullable = true)\n",
      " |-- Var227: string (nullable = true)\n",
      " |-- Var228: string (nullable = true)\n",
      " |-- Var229: string (nullable = true)\n",
      " |-- Label: integer (nullable = true)\n",
      " |-- Var192_index: double (nullable = true)\n",
      " |-- Var193_index: double (nullable = true)\n",
      " |-- Var195_index: double (nullable = true)\n",
      " |-- Var196_index: double (nullable = true)\n",
      " |-- Var197_index: double (nullable = true)\n",
      " |-- Var198_index: double (nullable = true)\n",
      " |-- Var199_index: double (nullable = true)\n",
      " |-- Var200_index: double (nullable = true)\n",
      " |-- Var202_index: double (nullable = true)\n",
      " |-- Var203_index: double (nullable = true)\n",
      " |-- Var204_index: double (nullable = true)\n",
      " |-- Var205_index: double (nullable = true)\n",
      " |-- Var206_index: double (nullable = true)\n",
      " |-- Var207_index: double (nullable = true)\n",
      " |-- Var208_index: double (nullable = true)\n",
      " |-- Var210_index: double (nullable = true)\n",
      " |-- Var211_index: double (nullable = true)\n",
      " |-- Var212_index: double (nullable = true)\n",
      " |-- Var214_index: double (nullable = true)\n",
      " |-- Var216_index: double (nullable = true)\n",
      " |-- Var217_index: double (nullable = true)\n",
      " |-- Var218_index: double (nullable = true)\n",
      " |-- Var219_index: double (nullable = true)\n",
      " |-- Var220_index: double (nullable = true)\n",
      " |-- Var221_index: double (nullable = true)\n",
      " |-- Var222_index: double (nullable = true)\n",
      " |-- Var223_index: double (nullable = true)\n",
      " |-- Var225_index: double (nullable = true)\n",
      " |-- Var226_index: double (nullable = true)\n",
      " |-- Var227_index: double (nullable = true)\n",
      " |-- Var228_index: double (nullable = true)\n",
      " |-- Var229_index: double (nullable = true)\n",
      " |-- Label_index: double (nullable = true)\n",
      " |-- Var192_indexvec: vector (nullable = true)\n",
      " |-- Var193_indexvec: vector (nullable = true)\n",
      " |-- Var195_indexvec: vector (nullable = true)\n",
      " |-- Var196_indexvec: vector (nullable = true)\n",
      " |-- Var197_indexvec: vector (nullable = true)\n",
      " |-- Var198_indexvec: vector (nullable = true)\n",
      " |-- Var199_indexvec: vector (nullable = true)\n",
      " |-- Var200_indexvec: vector (nullable = true)\n",
      " |-- Var202_indexvec: vector (nullable = true)\n",
      " |-- Var203_indexvec: vector (nullable = true)\n",
      " |-- Var204_indexvec: vector (nullable = true)\n",
      " |-- Var205_indexvec: vector (nullable = true)\n",
      " |-- Var206_indexvec: vector (nullable = true)\n",
      " |-- Var207_indexvec: vector (nullable = true)\n",
      " |-- Var208_indexvec: vector (nullable = true)\n",
      " |-- Var210_indexvec: vector (nullable = true)\n",
      " |-- Var211_indexvec: vector (nullable = true)\n",
      " |-- Var212_indexvec: vector (nullable = true)\n",
      " |-- Var214_indexvec: vector (nullable = true)\n",
      " |-- Var216_indexvec: vector (nullable = true)\n",
      " |-- Var217_indexvec: vector (nullable = true)\n",
      " |-- Var218_indexvec: vector (nullable = true)\n",
      " |-- Var219_indexvec: vector (nullable = true)\n",
      " |-- Var220_indexvec: vector (nullable = true)\n",
      " |-- Var221_indexvec: vector (nullable = true)\n",
      " |-- Var222_indexvec: vector (nullable = true)\n",
      " |-- Var223_indexvec: vector (nullable = true)\n",
      " |-- Var225_indexvec: vector (nullable = true)\n",
      " |-- Var226_indexvec: vector (nullable = true)\n",
      " |-- Var227_indexvec: vector (nullable = true)\n",
      " |-- Var228_indexvec: vector (nullable = true)\n",
      " |-- Var229_indexvec: vector (nullable = true)\n",
      " |-- Label_indexvec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_r.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selecting the required columns(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_list = []\n",
    "for name,dtype in df_r.dtypes:\n",
    "    if(name != 'Label'and name != 'Label_indexvec' and dtype != 'string' and name != 'Label_index' and name.endswith(\"_index\") != True):\n",
    "        features_list.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list of feature columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var6',\n",
       " 'Var7',\n",
       " 'Var13',\n",
       " 'Var21',\n",
       " 'Var22',\n",
       " 'Var24',\n",
       " 'Var25',\n",
       " 'Var28',\n",
       " 'Var35',\n",
       " 'Var38',\n",
       " 'Var44',\n",
       " 'Var57',\n",
       " 'Var65',\n",
       " 'Var72',\n",
       " 'Var73',\n",
       " 'Var74',\n",
       " 'Var76',\n",
       " 'Var78',\n",
       " 'Var81',\n",
       " 'Var83',\n",
       " 'Var85',\n",
       " 'Var94',\n",
       " 'Var109',\n",
       " 'Var112',\n",
       " 'Var113',\n",
       " 'Var119',\n",
       " 'Var123',\n",
       " 'Var125',\n",
       " 'Var126',\n",
       " 'Var132',\n",
       " 'Var133',\n",
       " 'Var134',\n",
       " 'Var140',\n",
       " 'Var143',\n",
       " 'Var144',\n",
       " 'Var149',\n",
       " 'Var153',\n",
       " 'Var160',\n",
       " 'Var163',\n",
       " 'Var173',\n",
       " 'Var181',\n",
       " 'Var189',\n",
       " 'Var192_indexvec',\n",
       " 'Var193_indexvec',\n",
       " 'Var195_indexvec',\n",
       " 'Var196_indexvec',\n",
       " 'Var197_indexvec',\n",
       " 'Var198_indexvec',\n",
       " 'Var199_indexvec',\n",
       " 'Var200_indexvec',\n",
       " 'Var202_indexvec',\n",
       " 'Var203_indexvec',\n",
       " 'Var204_indexvec',\n",
       " 'Var205_indexvec',\n",
       " 'Var206_indexvec',\n",
       " 'Var207_indexvec',\n",
       " 'Var208_indexvec',\n",
       " 'Var210_indexvec',\n",
       " 'Var211_indexvec',\n",
       " 'Var212_indexvec',\n",
       " 'Var214_indexvec',\n",
       " 'Var216_indexvec',\n",
       " 'Var217_indexvec',\n",
       " 'Var218_indexvec',\n",
       " 'Var219_indexvec',\n",
       " 'Var220_indexvec',\n",
       " 'Var221_indexvec',\n",
       " 'Var222_indexvec',\n",
       " 'Var223_indexvec',\n",
       " 'Var225_indexvec',\n",
       " 'Var226_indexvec',\n",
       " 'Var227_indexvec',\n",
       " 'Var228_indexvec',\n",
       " 'Var229_indexvec']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using vector assembler to zip the features columns into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=features_list,outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = assembler.transform(df_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a new dataframe with feature column and label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data = output.select('Label_index','features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schema of the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Label_index: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying decisontreeclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol='Label_index',featuresCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting 70% of data for training and 30% into testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data,test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schema of training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Label_index: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schema of test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Label_index: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first row of training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Label_index=0.0, features=SparseVector(71505, {0: 1176.0, 1: 7.0, 2: 1744.0, 3: 304.0, 4: 380.0, 5: 10.0, 6: 176.0, 7: 275.12, 8: 5.0, 9: 5681844.0, 10: 9.0, 11: 6.3074, 12: 18.0, 13: 3.0, 14: 40.0, 15: 84.0, 16: 2158176.0, 17: 9.0, 18: 146413.5, 19: 30.0, 20: 6.0, 21: 113649.0, 22: 104.0, 23: 96.0, 24: -609916.0, 25: 1275.0, 26: 84.0, 27: 21978.0, 28: 14.0, 29: 40.0, 30: 1699070.0, 31: 247190.0, 32: 1805.0, 34: 27.0, 35: 308266.0, 36: 8058320.0, 37: 38.0, 38: 42054.0, 41: 270.0, 138: 1.0, 402: 1.0, 452: 1.0, 474: 1.0, 506: 1.0, 1530: 1.0, 5082: 1.0, 10063: 1.0, 27500: 1.0, 31189: 1.0, 31227: 1.0, 31292: 1.0, 31295: 1.0, 31314: 1.0, 31327: 1.0, 31328: 1.0, 31333: 1.0, 31334: 1.0, 31414: 1.0, 46828: 1.0, 59895: 1.0, 62832: 1.0, 62833: 1.0, 63704: 1.0, 67144: 1.0, 67992: 1.0, 71440: 1.0, 71443: 1.0, 71455: 1.0, 71467: 1.0, 71473: 1.0, 71502: 1.0}))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first row of the test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Label_index=0.0, features=SparseVector(71505, {0: 1505.0, 1: 7.0, 2: 2148.0, 3: 156.0, 4: 195.0, 5: 2.0, 6: 80.0, 7: 253.52, 8: 5.0, 9: 2448.0, 10: 9.0, 11: 4.9959, 12: 18.0, 13: 3.0, 14: 130.0, 15: 224.0, 16: 1170240.0, 17: 3.0, 18: 13214.58, 19: 5.0, 20: 6.0, 21: 12159.0, 22: 48.0, 23: 48.0, 24: -93952.8, 25: 510.0, 26: 6.0, 27: 24273.0, 28: 4.0, 29: 24.0, 30: 2882780.0, 31: 322632.0, 32: 470.0, 34: 18.0, 35: 188272.0, 36: 3712616.0, 37: 36.0, 38: 246174.0, 41: 270.0, 71: 1.0, 403: 1.0, 453: 1.0, 474: 1.0, 602: 1.0, 775: 1.0, 4998: 1.0, 19499: 1.0, 26220: 1.0, 31189: 1.0, 31272: 1.0, 31292: 1.0, 31302: 1.0, 31314: 1.0, 31327: 1.0, 31328: 1.0, 31333: 1.0, 31335: 1.0, 43499: 1.0, 46831: 1.0, 55579: 1.0, 62833: 1.0, 62929: 1.0, 67144: 1.0, 67224: 1.0, 71441: 1.0, 71443: 1.0, 71465: 1.0, 71467: 1.0, 71474: 1.0, 71502: 1.0}))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## top 20rows of features column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(71505,[0,1,2,3,4...|\n",
      "|(71505,[0,3,4,5,6...|\n",
      "|(71505,[0,1,2,3,4...|\n",
      "|(71505,[0,3,5,7,1...|\n",
      "|(71505,[0,1,2,3,4...|\n",
      "|(71505,[0,1,2,3,4...|\n",
      "|(71505,[0,1,2,3,4...|\n",
      "|(71505,[0,3,4,5,6...|\n",
      "|(71505,[0,1,2,3,4...|\n",
      "|(71505,[0,1,2,3,4...|\n",
      "|(71505,[0,1,2,3,4...|\n",
      "|(71505,[0,1,2,3,4...|\n",
      "|(71505,[0,2,5,7,1...|\n",
      "|(71505,[0,3,4,5,6...|\n",
      "|(71505,[0,1,2,3,4...|\n",
      "|(71505,[0,2,3,4,7...|\n",
      "|(71505,[0,1,2,3,4...|\n",
      "|(71505,[0,1,2,3,4...|\n",
      "|(71505,[0,1,2,3,4...|\n",
      "|(71505,[0,1,3,4,5...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.select(final_data.columns[1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = dt.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predictions on the test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count of each class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|Label_index|count|\n",
      "+-----------+-----+\n",
      "|        0.0|46328|\n",
      "|        1.0| 3672|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.groupBy('Label_index').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schema of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Label_index: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = predictions.select(['prediction','Label_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using MulticlassMetrics for evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MulticlassMetrics(pl.rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True postive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00545950864422202"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy(positive rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9265914100594482"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confusion matrix evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = pl[(pl.Label_index == 1.0) & (pl.prediction == 1.0)].count()\n",
    "tn = pl[(pl.Label_index == 0.0) & (pl.prediction == 0.0)].count()\n",
    "fp = pl[(pl.Label_index == 0.0) & (pl.prediction == 1.0)].count()\n",
    "fn = pl[(pl.Label_index == 1.0) & (pl.prediction == 0.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive 6\n",
      "true negatives 13866\n",
      "false postives 6\n",
      "false negatives 1093\n"
     ]
    }
   ],
   "source": [
    "print(\"true positive\",tp)\n",
    "print(\"true negatives\",tn)\n",
    "print(\"false postives\",fp)\n",
    "print(\"false negatives\",fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## under Sampling to overcome class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selecting rows from majority class (number of rows equals to number of rows in minority class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_sample = output.sampleBy('Label_index',fractions={0: 3672.0/46328.0, 1: 1.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total number of rows after undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7268"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_sample.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of rows for each class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|Label_index|count|\n",
      "+-----------+-----+\n",
      "|        0.0| 3596|\n",
      "|        1.0| 3672|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "under_sample.groupBy('Label_index').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vector assembler to zip required columns into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_assembler = VectorAssembler(inputCols=features_list,outputCol=\"us_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_output = us_assembler.transform(under_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a new dataframe with feature column and label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_final_data = us_output.select('Label_index','us_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying decisontreeclassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_dt = DecisionTreeClassifier(labelCol='Label_index',featuresCol='us_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting 70% of data for training and 30% into testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_training_data,us_test_data = us_final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_model = us_dt.fit(us_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predictions on the test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_predictions = us_model.transform(us_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_pl = us_predictions.select(['prediction','Label_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using MulticlassMetrics for evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_metrics = MulticlassMetrics(us_pl.rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True postive rate for undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7027522935779816"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_metrics.recall(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confusion matrix evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = us_pl[(us_pl.Label_index == 1.0) & (us_pl.prediction == 1.0)].count()\n",
    "tn = us_pl[(us_pl.Label_index == 0.0) & (us_pl.prediction == 0.0)].count()\n",
    "fp = us_pl[(us_pl.Label_index == 0.0) & (us_pl.prediction == 1.0)].count()\n",
    "fn = us_pl[(us_pl.Label_index == 1.0) & (us_pl.prediction == 0.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive 766\n",
      "true negatives 580\n",
      "false postives 484\n",
      "false negatives 324\n"
     ]
    }
   ],
   "source": [
    "print(\"true positive\",tp)\n",
    "print(\"true negatives\",tn)\n",
    "print(\"false postives\",fp)\n",
    "print(\"false negatives\",fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy(positive rate) for undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6248839368616528"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_metrics.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## oversampling  to overcome class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selecting the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "minoriy_class = df_r.filter(df_r.Label_index == 1.0).select(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_rows = df_r.filter(df_r.Label_index == 0.0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_rows = df_r.filter(df_r.Label_index == 1.0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "replication = (majority_rows/minority_rows) -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replicating the minority class such that its proportion equals to majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sample = df_r\n",
    "i = 0\n",
    "while(i<replication):\n",
    "    over_sample = over_sample.union(minoriy_class)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of rows in each class after oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|Label_index|count|\n",
      "+-----------+-----+\n",
      "|        0.0|46328|\n",
      "|        1.0|47736|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "over_sample.groupBy('Label_index').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using vector assembler to zip required columns into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_assembler = VectorAssembler(inputCols=features_list,outputCol=\"os_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_output = os_assembler.transform(over_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selecting feature column and label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_final_data = os_output.select('Label_index','os_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_dt = DecisionTreeClassifier(labelCol='Label_index',featuresCol='os_features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting 70% of data for training and 30% into testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_training_data,os_test_data = os_final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_model = os_dt.fit(os_training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predictions on the test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_predictions = os_model.transform(os_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_pl = os_predictions.select(['prediction','Label_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using MulticlassMetrics for evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_metrics = MulticlassMetrics(os_pl.rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True positive rate for oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7287992693037307"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os_metrics.recall(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confusion matrix evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = os_pl[(os_pl.Label_index == 1.0) & (os_pl.prediction == 1.0)].count()\n",
    "tn = os_pl[(os_pl.Label_index == 0.0) & (os_pl.prediction == 0.0)].count()\n",
    "fp = os_pl[(os_pl.Label_index == 0.0) & (os_pl.prediction == 1.0)].count()\n",
    "fn = os_pl[(os_pl.Label_index == 1.0) & (os_pl.prediction == 0.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive 10373\n",
      "true negatives 7974\n",
      "false postives 5870\n",
      "false negatives 3860\n"
     ]
    }
   ],
   "source": [
    "print(\"true positive\",tp)\n",
    "print(\"true negatives\",tn)\n",
    "print(\"false postives\",fp)\n",
    "print(\"false negatives\",fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy(positive rate) for oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6534530042383445"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os_metrics.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
