{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification on the dataset where null values are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/abhi/spark-2.2.1-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('classifier').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe = spark.read.csv('/home/abhi/project/cleaned_data.csv',inferSchema=True,header=True,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schema of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Var6: integer (nullable = true)\n",
      " |-- Var7: integer (nullable = true)\n",
      " |-- Var13: integer (nullable = true)\n",
      " |-- Var21: integer (nullable = true)\n",
      " |-- Var22: integer (nullable = true)\n",
      " |-- Var24: integer (nullable = true)\n",
      " |-- Var25: integer (nullable = true)\n",
      " |-- Var28: double (nullable = true)\n",
      " |-- Var35: integer (nullable = true)\n",
      " |-- Var38: integer (nullable = true)\n",
      " |-- Var44: integer (nullable = true)\n",
      " |-- Var57: double (nullable = true)\n",
      " |-- Var65: integer (nullable = true)\n",
      " |-- Var72: integer (nullable = true)\n",
      " |-- Var73: integer (nullable = true)\n",
      " |-- Var74: integer (nullable = true)\n",
      " |-- Var76: integer (nullable = true)\n",
      " |-- Var78: integer (nullable = true)\n",
      " |-- Var81: double (nullable = true)\n",
      " |-- Var83: integer (nullable = true)\n",
      " |-- Var85: integer (nullable = true)\n",
      " |-- Var94: integer (nullable = true)\n",
      " |-- Var109: integer (nullable = true)\n",
      " |-- Var112: integer (nullable = true)\n",
      " |-- Var113: double (nullable = true)\n",
      " |-- Var119: integer (nullable = true)\n",
      " |-- Var123: integer (nullable = true)\n",
      " |-- Var125: integer (nullable = true)\n",
      " |-- Var126: integer (nullable = true)\n",
      " |-- Var132: integer (nullable = true)\n",
      " |-- Var133: integer (nullable = true)\n",
      " |-- Var134: integer (nullable = true)\n",
      " |-- Var140: integer (nullable = true)\n",
      " |-- Var143: integer (nullable = true)\n",
      " |-- Var144: integer (nullable = true)\n",
      " |-- Var149: integer (nullable = true)\n",
      " |-- Var153: integer (nullable = true)\n",
      " |-- Var160: integer (nullable = true)\n",
      " |-- Var163: integer (nullable = true)\n",
      " |-- Var173: integer (nullable = true)\n",
      " |-- Var181: integer (nullable = true)\n",
      " |-- Var189: integer (nullable = true)\n",
      " |-- Var192: string (nullable = true)\n",
      " |-- Var193: string (nullable = true)\n",
      " |-- Var195: string (nullable = true)\n",
      " |-- Var196: string (nullable = true)\n",
      " |-- Var197: string (nullable = true)\n",
      " |-- Var198: string (nullable = true)\n",
      " |-- Var199: string (nullable = true)\n",
      " |-- Var200: string (nullable = true)\n",
      " |-- Var202: string (nullable = true)\n",
      " |-- Var203: string (nullable = true)\n",
      " |-- Var204: string (nullable = true)\n",
      " |-- Var205: string (nullable = true)\n",
      " |-- Var206: string (nullable = true)\n",
      " |-- Var207: string (nullable = true)\n",
      " |-- Var208: string (nullable = true)\n",
      " |-- Var210: string (nullable = true)\n",
      " |-- Var211: string (nullable = true)\n",
      " |-- Var212: string (nullable = true)\n",
      " |-- Var214: string (nullable = true)\n",
      " |-- Var216: string (nullable = true)\n",
      " |-- Var217: string (nullable = true)\n",
      " |-- Var218: string (nullable = true)\n",
      " |-- Var219: string (nullable = true)\n",
      " |-- Var220: string (nullable = true)\n",
      " |-- Var221: string (nullable = true)\n",
      " |-- Var222: string (nullable = true)\n",
      " |-- Var223: string (nullable = true)\n",
      " |-- Var225: string (nullable = true)\n",
      " |-- Var226: string (nullable = true)\n",
      " |-- Var227: string (nullable = true)\n",
      " |-- Var228: string (nullable = true)\n",
      " |-- Var229: string (nullable = true)\n",
      " |-- Label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of attributes in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## number of rows in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rows = dataframe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3238"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classifying the columns based on the type of data present in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "string_list = []\n",
    "num_list = []\n",
    "for name,dtype in dataframe.dtypes:\n",
    "    if(dtype == 'string'):\n",
    "        string_list.append(name)\n",
    "    if(dtype != 'string'):\n",
    "        num_list.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## appending the column name label to string list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "string_list.append('Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list of the columns that contain categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var192',\n",
       " 'Var193',\n",
       " 'Var195',\n",
       " 'Var196',\n",
       " 'Var197',\n",
       " 'Var198',\n",
       " 'Var199',\n",
       " 'Var200',\n",
       " 'Var202',\n",
       " 'Var203',\n",
       " 'Var204',\n",
       " 'Var205',\n",
       " 'Var206',\n",
       " 'Var207',\n",
       " 'Var208',\n",
       " 'Var210',\n",
       " 'Var211',\n",
       " 'Var212',\n",
       " 'Var214',\n",
       " 'Var216',\n",
       " 'Var217',\n",
       " 'Var218',\n",
       " 'Var219',\n",
       " 'Var220',\n",
       " 'Var221',\n",
       " 'Var222',\n",
       " 'Var223',\n",
       " 'Var225',\n",
       " 'Var226',\n",
       " 'Var227',\n",
       " 'Var228',\n",
       " 'Var229',\n",
       " 'Label']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler,OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using string indexer to convert the categorical data into numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(dataframe) for column in string_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using pipeline to execute the operation in stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=indexers)\n",
    "df_r = pipeline.fit(dataframe).transform(dataframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the list of columns(categorical) that are converted into numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for name,dtype  in df_r.dtypes:\n",
    "    if(name.endswith('_index')):\n",
    "         index_list.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using onehotencoder to convert the categorical data into vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoders = [OneHotEncoder(inputCol=column, outputCol=column+\"vec\") for column in index_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=encoders)\n",
    "df_r = pipeline.fit(df_r).transform(df_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schema of the dataframe after applying onehotencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Var6: integer (nullable = true)\n",
      " |-- Var7: integer (nullable = true)\n",
      " |-- Var13: integer (nullable = true)\n",
      " |-- Var21: integer (nullable = true)\n",
      " |-- Var22: integer (nullable = true)\n",
      " |-- Var24: integer (nullable = true)\n",
      " |-- Var25: integer (nullable = true)\n",
      " |-- Var28: double (nullable = true)\n",
      " |-- Var35: integer (nullable = true)\n",
      " |-- Var38: integer (nullable = true)\n",
      " |-- Var44: integer (nullable = true)\n",
      " |-- Var57: double (nullable = true)\n",
      " |-- Var65: integer (nullable = true)\n",
      " |-- Var72: integer (nullable = true)\n",
      " |-- Var73: integer (nullable = true)\n",
      " |-- Var74: integer (nullable = true)\n",
      " |-- Var76: integer (nullable = true)\n",
      " |-- Var78: integer (nullable = true)\n",
      " |-- Var81: double (nullable = true)\n",
      " |-- Var83: integer (nullable = true)\n",
      " |-- Var85: integer (nullable = true)\n",
      " |-- Var94: integer (nullable = true)\n",
      " |-- Var109: integer (nullable = true)\n",
      " |-- Var112: integer (nullable = true)\n",
      " |-- Var113: double (nullable = true)\n",
      " |-- Var119: integer (nullable = true)\n",
      " |-- Var123: integer (nullable = true)\n",
      " |-- Var125: integer (nullable = true)\n",
      " |-- Var126: integer (nullable = true)\n",
      " |-- Var132: integer (nullable = true)\n",
      " |-- Var133: integer (nullable = true)\n",
      " |-- Var134: integer (nullable = true)\n",
      " |-- Var140: integer (nullable = true)\n",
      " |-- Var143: integer (nullable = true)\n",
      " |-- Var144: integer (nullable = true)\n",
      " |-- Var149: integer (nullable = true)\n",
      " |-- Var153: integer (nullable = true)\n",
      " |-- Var160: integer (nullable = true)\n",
      " |-- Var163: integer (nullable = true)\n",
      " |-- Var173: integer (nullable = true)\n",
      " |-- Var181: integer (nullable = true)\n",
      " |-- Var189: integer (nullable = true)\n",
      " |-- Var192: string (nullable = true)\n",
      " |-- Var193: string (nullable = true)\n",
      " |-- Var195: string (nullable = true)\n",
      " |-- Var196: string (nullable = true)\n",
      " |-- Var197: string (nullable = true)\n",
      " |-- Var198: string (nullable = true)\n",
      " |-- Var199: string (nullable = true)\n",
      " |-- Var200: string (nullable = true)\n",
      " |-- Var202: string (nullable = true)\n",
      " |-- Var203: string (nullable = true)\n",
      " |-- Var204: string (nullable = true)\n",
      " |-- Var205: string (nullable = true)\n",
      " |-- Var206: string (nullable = true)\n",
      " |-- Var207: string (nullable = true)\n",
      " |-- Var208: string (nullable = true)\n",
      " |-- Var210: string (nullable = true)\n",
      " |-- Var211: string (nullable = true)\n",
      " |-- Var212: string (nullable = true)\n",
      " |-- Var214: string (nullable = true)\n",
      " |-- Var216: string (nullable = true)\n",
      " |-- Var217: string (nullable = true)\n",
      " |-- Var218: string (nullable = true)\n",
      " |-- Var219: string (nullable = true)\n",
      " |-- Var220: string (nullable = true)\n",
      " |-- Var221: string (nullable = true)\n",
      " |-- Var222: string (nullable = true)\n",
      " |-- Var223: string (nullable = true)\n",
      " |-- Var225: string (nullable = true)\n",
      " |-- Var226: string (nullable = true)\n",
      " |-- Var227: string (nullable = true)\n",
      " |-- Var228: string (nullable = true)\n",
      " |-- Var229: string (nullable = true)\n",
      " |-- Label: integer (nullable = true)\n",
      " |-- Var192_index: double (nullable = true)\n",
      " |-- Var193_index: double (nullable = true)\n",
      " |-- Var195_index: double (nullable = true)\n",
      " |-- Var196_index: double (nullable = true)\n",
      " |-- Var197_index: double (nullable = true)\n",
      " |-- Var198_index: double (nullable = true)\n",
      " |-- Var199_index: double (nullable = true)\n",
      " |-- Var200_index: double (nullable = true)\n",
      " |-- Var202_index: double (nullable = true)\n",
      " |-- Var203_index: double (nullable = true)\n",
      " |-- Var204_index: double (nullable = true)\n",
      " |-- Var205_index: double (nullable = true)\n",
      " |-- Var206_index: double (nullable = true)\n",
      " |-- Var207_index: double (nullable = true)\n",
      " |-- Var208_index: double (nullable = true)\n",
      " |-- Var210_index: double (nullable = true)\n",
      " |-- Var211_index: double (nullable = true)\n",
      " |-- Var212_index: double (nullable = true)\n",
      " |-- Var214_index: double (nullable = true)\n",
      " |-- Var216_index: double (nullable = true)\n",
      " |-- Var217_index: double (nullable = true)\n",
      " |-- Var218_index: double (nullable = true)\n",
      " |-- Var219_index: double (nullable = true)\n",
      " |-- Var220_index: double (nullable = true)\n",
      " |-- Var221_index: double (nullable = true)\n",
      " |-- Var222_index: double (nullable = true)\n",
      " |-- Var223_index: double (nullable = true)\n",
      " |-- Var225_index: double (nullable = true)\n",
      " |-- Var226_index: double (nullable = true)\n",
      " |-- Var227_index: double (nullable = true)\n",
      " |-- Var228_index: double (nullable = true)\n",
      " |-- Var229_index: double (nullable = true)\n",
      " |-- Label_index: double (nullable = true)\n",
      " |-- Var192_indexvec: vector (nullable = true)\n",
      " |-- Var193_indexvec: vector (nullable = true)\n",
      " |-- Var195_indexvec: vector (nullable = true)\n",
      " |-- Var196_indexvec: vector (nullable = true)\n",
      " |-- Var197_indexvec: vector (nullable = true)\n",
      " |-- Var198_indexvec: vector (nullable = true)\n",
      " |-- Var199_indexvec: vector (nullable = true)\n",
      " |-- Var200_indexvec: vector (nullable = true)\n",
      " |-- Var202_indexvec: vector (nullable = true)\n",
      " |-- Var203_indexvec: vector (nullable = true)\n",
      " |-- Var204_indexvec: vector (nullable = true)\n",
      " |-- Var205_indexvec: vector (nullable = true)\n",
      " |-- Var206_indexvec: vector (nullable = true)\n",
      " |-- Var207_indexvec: vector (nullable = true)\n",
      " |-- Var208_indexvec: vector (nullable = true)\n",
      " |-- Var210_indexvec: vector (nullable = true)\n",
      " |-- Var211_indexvec: vector (nullable = true)\n",
      " |-- Var212_indexvec: vector (nullable = true)\n",
      " |-- Var214_indexvec: vector (nullable = true)\n",
      " |-- Var216_indexvec: vector (nullable = true)\n",
      " |-- Var217_indexvec: vector (nullable = true)\n",
      " |-- Var218_indexvec: vector (nullable = true)\n",
      " |-- Var219_indexvec: vector (nullable = true)\n",
      " |-- Var220_indexvec: vector (nullable = true)\n",
      " |-- Var221_indexvec: vector (nullable = true)\n",
      " |-- Var222_indexvec: vector (nullable = true)\n",
      " |-- Var223_indexvec: vector (nullable = true)\n",
      " |-- Var225_indexvec: vector (nullable = true)\n",
      " |-- Var226_indexvec: vector (nullable = true)\n",
      " |-- Var227_indexvec: vector (nullable = true)\n",
      " |-- Var228_indexvec: vector (nullable = true)\n",
      " |-- Var229_indexvec: vector (nullable = true)\n",
      " |-- Label_indexvec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_r.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selecting the required columns(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_list = []\n",
    "for name,dtype in df_r.dtypes:\n",
    "    if(name != 'Label'and name != 'Label_indexvec' and dtype != 'string' and name != 'Label_index' and name.endswith(\"_index\") != True):\n",
    "        features_list.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list of feature columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Var6',\n",
       " 'Var7',\n",
       " 'Var13',\n",
       " 'Var21',\n",
       " 'Var22',\n",
       " 'Var24',\n",
       " 'Var25',\n",
       " 'Var28',\n",
       " 'Var35',\n",
       " 'Var38',\n",
       " 'Var44',\n",
       " 'Var57',\n",
       " 'Var65',\n",
       " 'Var72',\n",
       " 'Var73',\n",
       " 'Var74',\n",
       " 'Var76',\n",
       " 'Var78',\n",
       " 'Var81',\n",
       " 'Var83',\n",
       " 'Var85',\n",
       " 'Var94',\n",
       " 'Var109',\n",
       " 'Var112',\n",
       " 'Var113',\n",
       " 'Var119',\n",
       " 'Var123',\n",
       " 'Var125',\n",
       " 'Var126',\n",
       " 'Var132',\n",
       " 'Var133',\n",
       " 'Var134',\n",
       " 'Var140',\n",
       " 'Var143',\n",
       " 'Var144',\n",
       " 'Var149',\n",
       " 'Var153',\n",
       " 'Var160',\n",
       " 'Var163',\n",
       " 'Var173',\n",
       " 'Var181',\n",
       " 'Var189',\n",
       " 'Var192_indexvec',\n",
       " 'Var193_indexvec',\n",
       " 'Var195_indexvec',\n",
       " 'Var196_indexvec',\n",
       " 'Var197_indexvec',\n",
       " 'Var198_indexvec',\n",
       " 'Var199_indexvec',\n",
       " 'Var200_indexvec',\n",
       " 'Var202_indexvec',\n",
       " 'Var203_indexvec',\n",
       " 'Var204_indexvec',\n",
       " 'Var205_indexvec',\n",
       " 'Var206_indexvec',\n",
       " 'Var207_indexvec',\n",
       " 'Var208_indexvec',\n",
       " 'Var210_indexvec',\n",
       " 'Var211_indexvec',\n",
       " 'Var212_indexvec',\n",
       " 'Var214_indexvec',\n",
       " 'Var216_indexvec',\n",
       " 'Var217_indexvec',\n",
       " 'Var218_indexvec',\n",
       " 'Var219_indexvec',\n",
       " 'Var220_indexvec',\n",
       " 'Var221_indexvec',\n",
       " 'Var222_indexvec',\n",
       " 'Var223_indexvec',\n",
       " 'Var225_indexvec',\n",
       " 'Var226_indexvec',\n",
       " 'Var227_indexvec',\n",
       " 'Var228_indexvec',\n",
       " 'Var229_indexvec']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using vector assembler to zip the features columns into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=features_list,outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = assembler.transform(df_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating a new dataframe with  feature column and label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_data = output.select('Label_index','features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schema of the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Label_index: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## applying decisontreeclassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol='Label_index',featuresCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting 70% of data for training and 30% into testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data,test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schema of training_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Label_index: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schema of test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Label_index: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first row of training_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Label_index=0.0, features=SparseVector(15055, {0: 1267.0, 1: 7.0, 2: 108.0, 3: 504.0, 4: 630.0, 5: 8.0, 6: 136.0, 7: 100.8, 8: 5.0, 9: 5759904.0, 10: 9.0, 11: 2.0598, 12: 9.0, 13: 3.0, 14: 52.0, 15: 35.0, 16: 1772592.0, 17: 6.0, 18: 103393.5, 19: 35.0, 20: 10.0, 21: 141747.0, 22: 64.0, 23: 104.0, 24: 184596.4, 25: 1985.0, 26: 186.0, 27: 7812.0, 28: -20.0, 29: 32.0, 30: 2932195.0, 31: 415204.0, 32: 850.0, 34: 9.0, 35: 515270.0, 36: 10199160.0, 37: 106.0, 38: 689622.0, 41: 306.0, 95: 1.0, 263: 1.0, 291: 1.0, 302: 1.0, 307: 1.0, 607: 1.0, 1458: 1.0, 4354: 1.0, 5500: 1.0, 7057: 1.0, 7069: 1.0, 7155: 1.0, 7165: 1.0, 7177: 1.0, 7185: 1.0, 7186: 1.0, 7190: 1.0, 7823: 1.0, 10263: 1.0, 10962: 1.0, 12975: 1.0, 13129: 1.0, 13992: 1.0, 14133: 1.0, 14999: 1.0, 15003: 1.0, 15004: 1.0, 15026: 1.0, 15032: 1.0, 15052: 1.0}))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first row of the test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Label_index=0.0, features=SparseVector(15055, {0: 2394.0, 1: 21.0, 2: 3836.0, 3: 208.0, 4: 260.0, 5: 4.0, 6: 72.0, 7: 114.64, 8: 5.0, 9: 2341650.0, 10: 9.0, 11: 5.4935, 12: 27.0, 13: 9.0, 14: 180.0, 15: 420.0, 16: 3136968.0, 17: 18.0, 18: 63711.3, 19: 5.0, 20: 18.0, 21: 125739.0, 22: 24.0, 23: 48.0, 24: -387325.2, 25: 1465.0, 26: 48.0, 27: 74808.0, 28: -30.0, 29: 72.0, 30: 2734495.0, 31: 241708.0, 32: 8300.0, 34: 36.0, 35: 1049167.0, 36: 6087000.0, 37: 38.0, 38: 345114.0, 40: 7.0, 41: 276.0, 151: 1.0, 263: 1.0, 291: 1.0, 302: 1.0, 315: 1.0, 455: 1.0, 1563: 1.0, 4438: 1.0, 5917: 1.0, 7057: 1.0, 7060: 1.0, 7155: 1.0, 7159: 1.0, 7178: 1.0, 7185: 1.0, 7186: 1.0, 7189: 1.0, 7191: 1.0, 9297: 1.0, 10267: 1.0, 12758: 1.0, 12974: 1.0, 12975: 1.0, 12991: 1.0, 13992: 1.0, 13998: 1.0, 14999: 1.0, 15002: 1.0, 15007: 1.0, 15027: 1.0, 15035: 1.0, 15052: 1.0}))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## top 20rows of features column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "|(15055,[0,1,2,3,4...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.select(final_data.columns[1]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = dt.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predictions on the test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count of each class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|Label_index|count|\n",
      "+-----------+-----+\n",
      "|        0.0| 3135|\n",
      "|        1.0|  103|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.groupBy('Label_index').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## schema of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Label_index: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = predictions.select(['prediction','Label_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using MulticlassMetrics for evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MulticlassMetrics(pl.rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True postive rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy(positive rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9623389494549058"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confusion matrix evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = pl[(pl.Label_index == 1.0) & (pl.prediction == 1.0)].count()\n",
    "tn = pl[(pl.Label_index == 0.0) & (pl.prediction == 0.0)].count()\n",
    "fp = pl[(pl.Label_index == 0.0) & (pl.prediction == 1.0)].count()\n",
    "fn = pl[(pl.Label_index == 1.0) & (pl.prediction == 0.0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive 0\n",
      "true negatives 971\n",
      "false postives 8\n",
      "false negatives 30\n"
     ]
    }
   ],
   "source": [
    "print(\"true positive\",tp)\n",
    "print(\"true negatives\",tn)\n",
    "print(\"false postives\",fp)\n",
    "print(\"false negatives\",fn)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
